---
#- name: Download spark
#  get_url: url=http://www.apache.org/dist/spark/spark-{{ spark_version }}/spark-{{ spark_version }}-bin-hadoop2.6.tgz dest=/opt/spark-{{ spark_version }}-bin-hadoop2.6.tgz

- name: Extract spark archive
  #command: tar xvfz /home/{{ cluster_user }}/spark-{{ spark_version }}-bin-hadoop2.6.tgz -C /opt #manual extract
  unarchive:
    #src: /opt/spark-{{ spark_version }}-bin-hadoop2.6.tgz #used if not using one time download
    src: apps/spark-{{ spark_version }}-bin-hadoop2.6.tgz
    dest: /opt
    creates: /opt/spark-{{ spark_version }}-bin-hadoop2.6
    copy: yes
    #copy: no #if not using one time download
    owner: "{{ cluster_user }}"
    group: "{{ cluster_user }}"

# Set permissions on the extracted archive if the tar command is used as opposed to unarchive with "copy: yes"
#- name: Set permissions on spark archive
#  file: path=/opt/spark-{{ spark_version }} state=directory owner={{ cluster_user }} group={{ cluster_user }}

- name: Create Spark current version symbolic link and assign ownsership
  file: path=/opt/spark src=/opt/spark-{{ spark_version }}-bin-hadoop2.6 state=link owner={{ cluster_user }} group={{ cluster_user }}

- name: Set SPARK_HOME in .bashrc
  lineinfile:
    dest: '/home/{{ cluster_user }}/.bashrc'
    line: 'export SPARK_HOME={{ spark_home }}'
    regexp: '^(# *)?export SPARK_HOME='
  become: yes
  become_user: "{{ cluster_user }}"

- name: Add PATH to SPARK_HOME/bin in .bashrc
  lineinfile:
    dest: '/home/{{ cluster_user }}/.bashrc'
    line: 'export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin # SPARK-BIN-PATH'
    regexp: '# SPARK-BIN-PATH'
  become: yes
  become_user: "{{ cluster_user }}"

- include: masternode.yml
  when: '"masters" in group_names'
